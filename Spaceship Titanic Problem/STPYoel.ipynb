{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'loss_curve_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 151\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(choose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    150\u001b[0m     choose \u001b[38;5;241m=\u001b[39m get_integer_option(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(algorithm_pack) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhich model to use?\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39malgorithm_option_string())\n\u001b[1;32m--> 151\u001b[0m     \u001b[43moutput_one_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchoose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m(choose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    153\u001b[0m     output_all_csv()\n",
      "Cell \u001b[1;32mIn[3], line 133\u001b[0m, in \u001b[0;36moutput_one_csv\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m    131\u001b[0m output_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPassengerId\u001b[39m\u001b[38;5;124m'\u001b[39m: passenger_ids, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransported\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions})\n\u001b[0;32m    132\u001b[0m output_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malgorithm_pack[i][\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 133\u001b[0m loss_values \u001b[38;5;241m=\u001b[39m \u001b[43malgorithm_pack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_curve_\u001b[49m\n\u001b[0;32m    134\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(loss_values)\n\u001b[0;32m    135\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss Curve\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'loss_curve_'"
     ]
    }
   ],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# -- Fungsi umum untuk semua permasalahan\n",
    "\n",
    "# Macam macam algoritma\n",
    "algorithm_pack = [[GaussianNB(), 'Naive Bayes', 'NB'],\n",
    "                [KNeighborsClassifier(), 'K Nearest Neighbors', 'KNN'],\n",
    "                [SVC(), 'Support Vector Machine','SVM'],\n",
    "                [LogisticRegression(), 'Logistic Regression', 'LR'],\n",
    "                [GradientBoostingClassifier(), 'Gradient Boosting', 'GB'],\n",
    "                [DecisionTreeClassifier(), 'Decision Tree', 'DT'],\n",
    "                [RandomForestClassifier(), 'Random Forest','RF'],\n",
    "                [MLPClassifier(max_iter=1000), 'Multi-layer Perceptron', 'MLP']  # Add MLP classifier here\n",
    "                ]\n",
    "\n",
    "# Fungsi untuk menampilkan opsi algoritma apa yang ingin dipakai\n",
    "def algorithm_option_string():\n",
    "    string = ''\n",
    "    for i in range(len(algorithm_pack)):\n",
    "        string += f\"\\n{i}. {algorithm_pack[i][1]}\"\n",
    "    string += '\\n['\n",
    "    for i in range(len(algorithm_pack)):\n",
    "        if(i == len(algorithm_pack) - 1):\n",
    "            string+= f\"{i}]: \"\n",
    "        else:\n",
    "            string+= f\"{i}/\"\n",
    "    return string\n",
    "\n",
    "# Fungsi untuk print error dengan warna merah dan diberi jarak\n",
    "def print_error(string):\n",
    "    print(\"\\n\\033[91m\"+string+\"\\033[0m\\n\")\n",
    "\n",
    "# Fungsi untuk validasi input opsi integer\n",
    "def get_integer_option(min_value, max_value, prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            value = int(input(prompt))\n",
    "            if min_value <= value <= max_value:\n",
    "                return value\n",
    "            else:\n",
    "                print_error(f\"Option must be between {min_value} and {max_value}\")\n",
    "        except ValueError:\n",
    "            print_error(f\"Invalid option. Please enter a valid integer value between {min_value} and {max_value}\")\n",
    "\n",
    "# Baca file test sama train\n",
    "train_data = pd.read_csv('csv/train.csv')\n",
    "test_data = pd.read_csv('csv/test.csv')\n",
    "\n",
    "# -- Variabel umum, dimodifikasi untuk kasus khusus, Tentukan kolom yang ingin di drop dan kolom yang menjadi target\n",
    "dropped_columns = ['PassengerId', 'HomePlanet', 'Destination', 'Age', 'VIP', 'Name', 'CryoSleep']\n",
    "target_column = 'Transported'\n",
    "\n",
    "# Ini untuk memilah fitur agar data mudah diolah kedepannya, fitur yang bersifat kategorikal dan fitur yang bersifat numerikal\n",
    "categorical_features = train_data.drop(columns=dropped_columns + [target_column]).select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = train_data.drop(columns=dropped_columns + [target_column]).select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "# Ini adalah fungsi transformasi yang digunakan untuk fitur kategorikal non ordinal\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),                           # Mengisi null value dengan data modus (yang sering muncul)\n",
    "    # Jika kode diatas tidak dipakai, berarti menggunakan unknown sebagai fitur\n",
    "    ('onehot', OneHotEncoder(sparse_output=False).set_output(transform='pandas'))   # Setelah diisi datanya\n",
    "])                                                                                  # OneHotEncoder mengubah kategorikal menjadi biner (numerikal)\n",
    "\n",
    "# Ini adalah fungsi transformasi yang digunakan untuk fitur numerikal non ordinal\n",
    "numerical_imputer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))               # Mengisi null value dengan data median\n",
    "])\n",
    "\n",
    "# Untuk menggabungkan kedua transformasi pada 1 step\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('num', numerical_imputer, numerical_features)\n",
    "    ])\n",
    "\n",
    "# Agar proses lebih sinkron dan mengurangi kemungkinan terjadinya kesalahan pada sinkronisasi data\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# -- Fungsi khusus permasalahan\n",
    "\n",
    "# Fungsi buat ngambil huruf S sama P di Side\n",
    "def extract_last_cabin_part(s):\n",
    "    if isinstance(s, str):\n",
    "        parts = s.split('/')\n",
    "        return parts[-1]\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "# Membersihkan data buat di training\n",
    "\n",
    "# Drop kolom yang tidak relevan menurut persepsi kelompok terhadap soal (train.csv)\n",
    "x_train = train_data.drop(columns=dropped_columns + [target_column])\n",
    "y_train = train_data[target_column]\n",
    "\n",
    "# -- Fungsi khusus lakukan pembersihan data lanjutan sesuai logika yang dianggap benar (train.csv)\n",
    "x_train['Cabin'] = x_train['Cabin'].apply(extract_last_cabin_part)\n",
    "\n",
    "# Mengubah dari data mentah ke data yang akan dilatih (train.csv)\n",
    "transformed_X_train = pipeline.fit_transform(x_train)\n",
    "\n",
    "# Drop kolom yang tidak relevan menurut persepsi kelompok terhadap soal (test.csv)\n",
    "x_test = test_data.drop(columns=dropped_columns)\n",
    "\n",
    "# -- Fungsi khusus lakukan pembersihan data lanjutan sesuai logika yang dianggap benar (test.csv)\n",
    "x_test['Cabin'] = x_test['Cabin'].apply(extract_last_cabin_part)\n",
    "\n",
    "# Mengubah dari data mentah ke data yang akan di uji coba (test.csv)\n",
    "transformed_X_test = pipeline.transform(x_test)\n",
    "\n",
    "# -- Fungsi umum permasalahan namun harus disesuaikan dengan output yang diminta oleh soal\n",
    "# fungsi fungsi berikut hanya untuk memudahkan output\n",
    "\n",
    "def output_one_csv(i):\n",
    "    algorithm_pack[i][0].fit(transformed_X_train, y_train)\n",
    "    predictions = algorithm_pack[i][0].predict(transformed_X_test)\n",
    "    passenger_ids = test_data['PassengerId']\n",
    "    output_df = pd.DataFrame({'PassengerId': passenger_ids, 'Transported': predictions})\n",
    "    output_df.to_csv(f'predictions_{algorithm_pack[i][2]}.csv', index=False)\n",
    "    \n",
    "def output_all_csv():\n",
    "    for i in range(len(algorithm_pack)):\n",
    "        output_one_csv(i)\n",
    "\n",
    "# Chose what do you want to do?\n",
    "choose = get_integer_option(0, 2, \"What do you want to do with the csv?\\n0. Train the csv data\\n1. Get the info of the csv data\\n2. Get the csv of clean preprocessed data\\n[0/1/2]: \")\n",
    "\n",
    "if(choose == 0):\n",
    "    choose = get_integer_option(0, 1, \"Use all model?\\n0. No\\n1. Yes\\n[0/1]: \")\n",
    "    if(choose == 0):\n",
    "        choose = get_integer_option(0, len(algorithm_pack) - 1, f\"Which model to use?\"+algorithm_option_string())\n",
    "        output_one_csv(choose)\n",
    "    elif(choose == 1):\n",
    "        output_all_csv()\n",
    "elif(choose == 1):\n",
    "    print(\"Training data info:\\n\",train_data.dtypes,\"\\n\")\n",
    "    print(\"Test data info:\\n\",test_data.dtypes)\n",
    "elif(choose == 2):\n",
    "    # Ambil nama dari kategorikal yang sudah di OneHotEncode\n",
    "    encoded_categorical_columns = pipeline.named_steps['preprocessor'].transformers_[0][1] \\\n",
    "                                .named_steps['onehot'].get_feature_names_out(categorical_features)\n",
    "\n",
    "    # menggabungkan nama kolom untuk fitur kategorikal dan fitur numerikal (termasuk 'PassengerId')\n",
    "    all_column_names = list(encoded_categorical_columns) + numerical_features\n",
    "\n",
    "    # Memberikan nama kolom ke data yang sudah dibersihkan sebelum diproses\n",
    "    clean_data_df = pd.DataFrame(transformed_X_train)\n",
    "    clean_data_df.columns = all_column_names\n",
    "    clean_data_df.to_csv('clean_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_columns = ['PassengerId', 'HomePlanet', 'Destination', 'Age', 'VIP', 'Name']\n",
    "target_column = 'Transported'\n",
    "\n",
    "def extract_last_cabin_part(s):\n",
    "    if isinstance(s, str):\n",
    "        parts = s.split('/')\n",
    "        return parts[-1]\n",
    "    else:\n",
    "        return 'U'\n",
    "\n",
    "x_train['Cabin'] = x_train['Cabin'].apply(extract_last_cabin_part)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
